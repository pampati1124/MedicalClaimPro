📍 Objective
Build a simplified, real-world agentic backend pipeline that processes medical insurance claim documents using AI tools and agent orchestration frameworks.
This assignment evaluates your ability to:
Architect backend systems with multi-agent workflows


Use AI developer tools like ChatGPT, Claude, Gemini, and Cursor effectively


Implement modular, testable Python code using FastAPI


Understand and explain your code and design choices



🧠 What You’ll Build: Claim Document Processor (Mini Engine)
🔄 Endpoint: /process-claim
A single FastAPI endpoint that:
Accepts multiple PDF files (e.g., bill, ID card, discharge summary)


Classifies each PDF using an LLM-based agent (based on filename/content)


Extracts text using LLM like gemini


Processes extracted text using multiple AI agents (e.g., BillAgent, DischargeAgent)


Structures the text into a defined JSON schema


Validates the structured output for missing data or inconsistencies


Returns a final claim decision (approve/reject) with reasons



🔧 Tech Requirements
FastAPI backend using async where appropriate


Use either:


LangGraph, Google Agent development kit, or your own agent orchestration logic


Use LLMs for classification, extraction, and validation steps (GPT / Claude / Gemini etc.)


File upload support (multipart/form-data)


Code should be modular, clean, and organized (you may include tests if you’d like)




🤖 AI Tool Usage – Mandatory
This assignment requires the use of:
Cursor.ai (or similar AI coding assistant)


ChatGPT, Claude, or Gemini for code scaffolding, prompting, debugging, and architecture decisions


You must:
Document which tools you used and how


Share at least 2–3 prompt examples you used (in README)



🗃️ Example JSON Output
{
  "documents": [
    {
      "type": "bill",
      "hospital_name": "ABC Hospital",
      "total_amount": 12500,
      "date_of_service": "2024-04-10"
    },
    {
      "type": "discharge_summary",
      "patient_name": "John Doe",
      "diagnosis": "Fracture",
      "admission_date": "2024-04-01",
      "discharge_date": "2024-04-10"
    }
  ],
  "validation": {
    "missing_documents": [],
    "discrepancies": []
  },
  "claim_decision": {
    "status": "approved",
    "reason": "All required documents present and data is consistent"
  }
}


Sample Docs for testing:
Link: https://drive.google.com/drive/folders/10h_JxEn91Zrhgzr30bvXUmFjS_4y2I8T?usp=sharing

📁 Deliverables
GitHub repo (or ZIP) with:


Code (FastAPI + agent orchestration logic)


README.md explaining:


Architecture & logic


Where and how you used AI tools


At least 2–3 actual prompt examples used


[Optional] A 2–3 min Loom/video explaining your project and what AI tools helped with


Bonus if you include: Dockerfile, Redis/PG setup, or vector store usage



🧪 Evaluation Criteria (Out of 120)
Criteria
Points
Agent architecture & orchestration logic
25
Clean modular code, async FastAPI
20
Thoughtful LLM prompt design & parsing
20
Validation + cross-check logic
15
Usage of AI tools (well-integrated + documented)
15
README clarity + architecture explanation
10
Bonus: Loom, Docker, PG/Redis vector store
10
Bonus: They explain failures & tradeoffs
5



⏳ Deadline
The deadline for submitting your solution is three days from the date this assignment was emailed.

🔎 Next Steps After Submission
If shortlisted:
You’ll be invited to a 45–60 min session


We’ll discuss:


How you used AI tools


Why you made certain design choices


Live debugging or small change implementation


Your understanding of agentic workflows



🧠 Remember
We’re not just evaluating raw coding. We’re looking for engineers who:
Move fast using modern tools


Think clearly and explain their decisions


Understand LLMs, agents, and asynchronous systems


Take ownership and build like a product engineer
